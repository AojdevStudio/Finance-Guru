---
phase: 05-agent-readiness-hardening
plan: 06
type: execute
wave: 3
depends_on: ["05-03"]
files_modified:
  - tests/python/test_correlation_calc.py
  - tests/python/test_risk_metrics_module.py
  - tests/python/test_backtester.py
  - tests/python/test_optimizer.py
autonomous: true

must_haves:
  truths:
    - "correlation.py has test coverage above 80%"
    - "risk_metrics.py has test coverage above 80%"
    - "backtester.py has test coverage above 80%"
    - "optimizer.py has test coverage above 80%"
  artifacts:
    - path: "tests/python/test_correlation_calc.py"
      provides: "Tests for correlation calculator"
      contains: "class TestCorrelation"
    - path: "tests/python/test_risk_metrics_module.py"
      provides: "Tests for RiskCalculator class"
      contains: "class TestRiskCalculator"
    - path: "tests/python/test_backtester.py"
      provides: "Tests for backtesting engine"
      contains: "class TestBacktester"
    - path: "tests/python/test_optimizer.py"
      provides: "Tests for portfolio optimizer"
      contains: "class TestOptimizer"
  key_links:
    - from: "tests/python/test_risk_metrics_module.py"
      to: "src/analysis/risk_metrics.py"
      via: "import and test RiskCalculator"
      pattern: "from src.analysis.risk_metrics import"
    - from: "tests/python/test_backtester.py"
      to: "src/strategies/backtester.py"
      via: "import and test Backtester"
      pattern: "from src.strategies.backtester import"
---

<objective>
Write comprehensive test suites for the four analysis and strategy calculator modules (correlation, risk_metrics, backtester, optimizer) to bring them from 0% to 80%+ coverage.

Purpose: These are the core Layer 2 financial calculators. Testing them contributes ~593 statements toward the 80% coverage target.
Output: Four new test files in tests/python/.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/codebase/TESTING.md
@src/analysis/correlation.py
@src/analysis/risk_metrics.py
@src/strategies/backtester.py
@src/strategies/optimizer.py
@src/models/correlation_inputs.py
@src/models/risk_inputs.py
@src/models/backtest_inputs.py
@src/models/portfolio_inputs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write tests for correlation.py and risk_metrics.py</name>
  <files>
    tests/python/test_correlation_calc.py
    tests/python/test_risk_metrics_module.py
  </files>
  <action>
  Read src/analysis/correlation.py (110 stmts) and src/analysis/risk_metrics.py (127 stmts), then write test suites.

  NOTE: test_risk_metrics.py already exists (tests basic formulas). Name the new file test_risk_metrics_module.py to test the actual RiskCalculator class.

  **For test_correlation_calc.py:**
  1. Read correlation.py to understand the correlation calculation function/class
  2. Create mock multi-ticker price data (2-5 tickers with known correlations)
  3. Test:
     - Pearson correlation matrix computation (perfectly correlated = 1.0, inverse = -1.0)
     - Covariance matrix
     - Diversification ratio
     - Concentration metrics
     - Rolling correlation (if present)
  4. Test edge cases: single ticker, identical tickers, insufficient data
  5. Mock yfinance calls -- use synthetic price data only
  6. Verify Pydantic output models

  **For test_risk_metrics_module.py:**
  1. Read risk_metrics.py to understand RiskCalculator class methods
  2. Create mock price/returns data with known statistical properties
  3. Test each metric:
     - VaR (Value at Risk) at 95% and 99% confidence
     - CVaR (Conditional VaR / Expected Shortfall)
     - Sharpe ratio (verify against known manual calculation)
     - Sortino ratio
     - Maximum drawdown (known peak-to-trough)
     - Calmar ratio
     - Volatility (annualized)
     - Beta and Alpha (with mock benchmark data)
  4. Test with known-answer data: e.g., constant returns should give zero volatility, Sharpe = inf or handled
  5. Test error conditions: empty data, insufficient points

  **Known-answer pattern:**
  ```python
  def test_sharpe_ratio_known_answer(self):
      """10% return, 2% risk-free, 15% vol => Sharpe = 0.533"""
      # Create returns with known mean and std
      np.random.seed(42)
      daily_returns = np.random.normal(0.10/252, 0.15/np.sqrt(252), 252)
      # ... pass to calculator, verify result within tolerance
  ```
  </action>
  <verify>
  - `uv run pytest tests/python/test_correlation_calc.py tests/python/test_risk_metrics_module.py -v` passes
  - `uv run pytest tests/python/test_correlation_calc.py --cov=src/analysis/correlation --cov-report=term-missing` shows >= 80%
  - `uv run pytest tests/python/test_risk_metrics_module.py --cov=src/analysis/risk_metrics --cov-report=term-missing` shows >= 80%
  </verify>
  <done>test_correlation_calc.py covers correlation.py at 80%+. test_risk_metrics_module.py covers risk_metrics.py at 80%+. All tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Write tests for backtester.py and optimizer.py</name>
  <files>
    tests/python/test_backtester.py
    tests/python/test_optimizer.py
  </files>
  <action>
  Read src/strategies/backtester.py (148 stmts) and src/strategies/optimizer.py (208 stmts), then write test suites.

  **For test_backtester.py:**
  1. Read backtester.py to understand the Backtester class and strategies
  2. Create mock price data for backtesting (100-252 days of daily prices)
  3. Test each strategy type:
     - RSI strategy (buy oversold, sell overbought)
     - SMA crossover strategy (golden cross / death cross)
     - Buy-and-hold benchmark
  4. Test output metrics:
     - Total return calculation
     - Sharpe ratio of strategy
     - Win rate (% of profitable trades)
     - Maximum drawdown during backtest
  5. Test with flat market (no trades), trending market (clear signals), choppy market
  6. Test commission and slippage deductions
  7. Mock any external data fetching

  **For test_optimizer.py:**
  1. Read optimizer.py to understand PortfolioOptimizer class
  2. Create mock return data for 3-5 assets with known covariance structure
  3. Test each optimization method:
     - Maximum Sharpe ratio portfolio
     - Minimum variance portfolio
     - Risk parity portfolio
     - Mean-variance optimization
     - Black-Litterman (if present)
  4. Test constraints: max position size, weights sum to 1.0, no negative weights
  5. Test edge cases: single asset, perfectly correlated assets, degenerate covariance matrix
  6. Mock yfinance -- use synthetic return data only
  7. Verify output weights are valid (sum to 1, within bounds)

  **Use scipy.optimize mock if needed to speed up tests:**
  The optimizer likely uses scipy.optimize.minimize. For unit tests, verify the inputs to the optimizer are correct and that results are post-processed correctly.
  </action>
  <verify>
  - `uv run pytest tests/python/test_backtester.py tests/python/test_optimizer.py -v` passes
  - `uv run pytest tests/python/test_backtester.py --cov=src/strategies/backtester --cov-report=term-missing` shows >= 80%
  - `uv run pytest tests/python/test_optimizer.py --cov=src/strategies/optimizer --cov-report=term-missing` shows >= 80%
  </verify>
  <done>test_backtester.py covers backtester.py at 80%+. test_optimizer.py covers optimizer.py at 80%+. All tests pass.</done>
</task>

</tasks>

<verification>
1. All four new test files pass
2. Each source module has >= 80% coverage individually
3. Full test suite still passes: `uv run pytest -x -q`
</verification>

<success_criteria>
Four new test files written and passing. correlation.py, risk_metrics.py, backtester.py, and optimizer.py each have 80%+ test coverage.
</success_criteria>

<output>
After completion, create `.planning/phases/05-agent-readiness-hardening/05-06-SUMMARY.md`
</output>
