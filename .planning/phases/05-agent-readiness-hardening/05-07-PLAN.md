---
phase: 05-agent-readiness-hardening
plan: 07
type: execute
wave: 3
depends_on: ["05-03"]
files_modified:
  - tests/python/test_momentum_cli.py
  - tests/python/test_volatility_cli.py
  - tests/python/test_moving_averages_cli.py
  - tests/python/test_yaml_generator_cli.py
  - tests/python/test_input_validation_cli.py
autonomous: true

must_haves:
  truths:
    - "momentum_cli.py has test coverage above 75%"
    - "volatility_cli.py has test coverage above 75%"
    - "moving_averages_cli.py has test coverage above 75%"
    - "yaml_generator_cli.py has test coverage above 75%"
    - "input_validation_cli.py has test coverage above 75%"
  artifacts:
    - path: "tests/python/test_momentum_cli.py"
      provides: "Tests for momentum CLI"
      contains: "class TestMomentumCLI"
    - path: "tests/python/test_volatility_cli.py"
      provides: "Tests for volatility CLI"
      contains: "class TestVolatilityCLI"
    - path: "tests/python/test_moving_averages_cli.py"
      provides: "Tests for moving averages CLI"
      contains: "class TestMovingAveragesCLI"
    - path: "tests/python/test_yaml_generator_cli.py"
      provides: "Tests for YAML generator CLI"
      contains: "class TestYAMLGeneratorCLI"
    - path: "tests/python/test_input_validation_cli.py"
      provides: "Tests for input validation CLI"
      contains: "class TestInputValidationCLI"
  key_links:
    - from: "tests/python/test_momentum_cli.py"
      to: "src/utils/momentum_cli.py"
      via: "import and test CLI functions"
      pattern: "from src.utils.momentum_cli import|momentum_cli"
---

<objective>
Write test suites for five utility CLI scripts (momentum, volatility, moving_averages, yaml_generator, input_validation) to bring them from 0% to 75%+ coverage each.

Purpose: CLI scripts are Layer 3 (I/O only) and follow repetitive patterns. Testing them contributes ~851 statements toward the 80% coverage target.
Output: Five new test files in tests/python/.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/codebase/TESTING.md
@.planning/codebase/CONVENTIONS.md
@src/utils/momentum_cli.py
@src/utils/volatility_cli.py
@src/utils/moving_averages_cli.py
@src/utils/yaml_generator_cli.py
@src/utils/input_validation_cli.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write tests for momentum_cli.py and volatility_cli.py</name>
  <files>
    tests/python/test_momentum_cli.py
    tests/python/test_volatility_cli.py
  </files>
  <action>
  Read src/utils/momentum_cli.py (228 stmts) and src/utils/volatility_cli.py (131 stmts), then write test suites.

  **CLI testing strategy** (applies to ALL CLI test files in this plan):
  All CLI scripts follow the same Layer 3 pattern: parse_args() + main() that calls a Layer 2 calculator. Test by:
  1. Testing parse_args() with various argument combinations
  2. Mocking the calculator class and yfinance to test main() flow
  3. Testing output formatting (text and JSON modes)
  4. Testing error handling (invalid ticker, network error)
  5. Testing --help output contains expected text

  **For test_momentum_cli.py:**
  1. Read momentum_cli.py to identify:
     - parse_args() function and all supported flags
     - main() function flow
     - Output formatting functions
  2. Test parse_args:
     - Valid: `["TSLA"]`, `["TSLA", "--days", "90"]`, `["TSLA", "--output", "json"]`, `["TSLA", "--indicator", "rsi"]`
     - Verify default values (days=90, output=text, etc.)
  3. Test main() with mocked calculator:
     ```python
     @patch("src.utils.momentum_cli.MomentumCalculator")
     @patch("src.utils.momentum_cli.yf.Ticker")
     def test_main_text_output(self, mock_yf, mock_calc):
         mock_yf.return_value.history.return_value = self._mock_prices()
         mock_calc.return_value.calculate_all.return_value = self._mock_results()
         # Capture stdout, verify output format
     ```
  4. Test error handling (mock raising ValueError)
  5. Test JSON output mode

  **For test_volatility_cli.py:**
  - Same pattern as momentum_cli. Test parse_args, main with mocks, output modes, error handling.
  - Test specific volatility flags: --atr-period, --bb-period, --bb-std

  **Use capsys or StringIO to capture output:**
  ```python
  def test_text_output_format(self, capsys):
      # ... run main with mocked deps
      captured = capsys.readouterr()
      assert "Momentum Analysis" in captured.out  # or appropriate header
  ```
  </action>
  <verify>
  - `uv run pytest tests/python/test_momentum_cli.py tests/python/test_volatility_cli.py -v` passes
  - `uv run pytest tests/python/test_momentum_cli.py --cov=src/utils/momentum_cli --cov-report=term-missing` shows >= 75%
  - `uv run pytest tests/python/test_volatility_cli.py --cov=src/utils/volatility_cli --cov-report=term-missing` shows >= 75%
  </verify>
  <done>test_momentum_cli.py covers momentum_cli.py at 75%+. test_volatility_cli.py covers volatility_cli.py at 75%+.</done>
</task>

<task type="auto">
  <name>Task 2: Write tests for moving_averages_cli.py, yaml_generator_cli.py, and input_validation_cli.py</name>
  <files>
    tests/python/test_moving_averages_cli.py
    tests/python/test_yaml_generator_cli.py
    tests/python/test_input_validation_cli.py
  </files>
  <action>
  Read the three CLI files and write test suites following the same pattern as Task 1.

  **For test_moving_averages_cli.py (296 stmts -- largest CLI):**
  1. Read moving_averages_cli.py. This is the largest CLI; focus on the main code paths.
  2. Test parse_args with all flag combinations: --ma-type, --period, --fast, --slow
  3. Mock MovingAverageCalculator and yfinance
  4. Test each output section (single MA, crossover, comparison)
  5. Test error handling paths
  6. Target 75% -- the display/formatting functions can have lower coverage if core logic is well-tested

  **For test_yaml_generator_cli.py (91 stmts):**
  1. Read yaml_generator_cli.py
  2. Test parse_args
  3. Mock YAMLGenerator class
  4. Test main flow: input collection -> generation -> output
  5. Test file output mode if present

  **For test_input_validation_cli.py (105 stmts):**
  1. Read input_validation_cli.py
  2. Test parse_args (ticker argument, --days flag)
  3. Mock DataValidator and market data fetching
  4. Test validation result display (clean data vs data with issues)
  5. Test error handling

  **Important for moving_averages_cli.py:** This file has known None-handling issues (fixed in Plan 03 mypy task). The tests should verify the None guards work correctly. Include tests where optional parameters are None.
  </action>
  <verify>
  - `uv run pytest tests/python/test_moving_averages_cli.py tests/python/test_yaml_generator_cli.py tests/python/test_input_validation_cli.py -v` passes
  - Individual coverage checks show >= 75% for each CLI module
  </verify>
  <done>Three CLI test files written and passing. moving_averages_cli.py, yaml_generator_cli.py, and input_validation_cli.py each at 75%+ coverage.</done>
</task>

</tasks>

<verification>
1. All five new test files pass
2. Each CLI module has >= 75% coverage
3. Full test suite still passes: `uv run pytest -x -q`
</verification>

<success_criteria>
Five new CLI test files written and passing. All five utility CLIs at 75%+ test coverage.
</success_criteria>

<output>
After completion, create `.planning/phases/05-agent-readiness-hardening/05-07-SUMMARY.md`
</output>
