---
phase: 03-onboarding-wizard
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/cli/onboarding_wizard.py
  - .claude/hooks/load-fin-core-config.ts
  - tests/python/test_onboarding_validators.py
  - tests/python/test_onboarding_sections.py
  - tests/python/test_onboarding_wizard.py
autonomous: true

must_haves:
  truths:
    - "User completes 8-section interactive onboarding and a valid user-profile.yaml is generated in fin-guru-private/ with their financial data"
    - "Entering invalid input shows a clear error and re-prompts up to 3 times, then offers a skip option"
    - "CLAUDE.md is generated with the user's name and correct project-root path (no hardcoded personal names or absolute paths)"
    - ".env file is created with optional API keys (user can skip all keys and system still functions)"
    - "MCP.json is generated from template with backup of existing file"
    - "Finance Guru agents load the generated user-profile.yaml and address the user by their configured name"
  artifacts:
    - path: "src/cli/onboarding_wizard.py"
      provides: "Main wizard entry point: orchestrates 8 sections, converts state to UserDataInput, generates all config files"
      min_lines: 100
    - path: "tests/python/test_onboarding_validators.py"
      provides: "Unit tests for retry-with-skip wrapper and all domain validators"
      min_lines: 60
    - path: "tests/python/test_onboarding_sections.py"
      provides: "Unit tests for section runners with mocked questionary prompts"
      min_lines: 80
    - path: "tests/python/test_onboarding_wizard.py"
      provides: "Integration test for full wizard flow with mocked questionary"
      min_lines: 50
  key_links:
    - from: "src/cli/onboarding_wizard.py"
      to: "src/utils/onboarding_sections.py"
      via: "imports all 8 run_*_section functions"
      pattern: "from src\\.utils\\.onboarding_sections import"
    - from: "src/cli/onboarding_wizard.py"
      to: "src/models/yaml_generation_inputs.py"
      via: "converts OnboardingState.data to UserDataInput for generation"
      pattern: "UserDataInput\\("
    - from: "src/cli/onboarding_wizard.py"
      to: "src/utils/yaml_generator.py"
      via: "calls YAMLGenerator.generate_all_configs() and write_config_files()"
      pattern: "generate_all_configs|write_config_files"
    - from: "src/cli/onboarding_wizard.py"
      to: ".claude/mcp.json"
      via: "explicit Path('.claude/mcp.json').write_text(output.mcp_json)"
      pattern: "Path.*mcp\\.json.*write_text"
    - from: ".claude/hooks/load-fin-core-config.ts"
      to: "fin-guru-private/fin-guru/data/user-profile.yaml"
      via: "profilePath reads from fin-guru-private/ (updated to match wizard output path)"
      pattern: "fin-guru-private/fin-guru/data/user-profile\\.yaml"
    - from: "tests/python/test_onboarding_sections.py"
      to: "questionary"
      via: "mocker.patch at questionary function level (not stdin)"
      pattern: "mocker\\.patch.*questionary"
---

<objective>
Build the wizard CLI entry point that orchestrates all 8 sections, converts collected data into the existing Pydantic models, generates all config files (user-profile.yaml, CLAUDE.md, .env, MCP JSON) to the correct output locations, fix the hook profile path mismatch so agents load the generated profile at runtime, and write comprehensive tests for the entire onboarding stack.

Purpose: This completes the interactive onboarding wizard (ONBD-01, ONBD-04, ONBD-07, ONBD-08, ONBD-09) by wiring the section runners from Plan 01 into a complete CLI flow that produces real configuration files. The hook path fix ensures ONBD-17 is satisfied at runtime (agents address user by configured name). Tests verify validators, sections, and the full wizard pipeline (ONBD-02, XC-04).

Output: Working CLI at `src/cli/onboarding_wizard.py` callable via `uv run python src/cli/onboarding_wizard.py`, updated hook at `.claude/hooks/load-fin-core-config.ts` with corrected profile path, plus 3 test files covering validators, sections, and integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-onboarding-wizard/03-RESEARCH.md
@.planning/phases/03-onboarding-wizard/03-01-SUMMARY.md

# Files from Plan 01 (created by this plan's dependency)
@src/models/onboarding_inputs.py
@src/utils/onboarding_validators.py
@src/utils/onboarding_sections.py

# Existing Layer 1+2 (reused, NOT modified)
@src/models/yaml_generation_inputs.py
@src/utils/yaml_generator.py
@src/utils/yaml_generator_cli.py

# Hook that loads user profile at session start (WILL be modified -- path fix)
@.claude/hooks/load-fin-core-config.ts

# Templates (used by YAMLGenerator)
# scripts/onboarding/modules/templates/ contains: user-profile.template.yaml, CLAUDE.template.md, env.template, mcp.template.json, config.template.yaml, system-context.template.md

# Existing test patterns
@tests/python/test_yaml_generation.py

# TypeScript env-setup and summary sections (reference for output behavior)
@scripts/onboarding/sections/env-setup.ts
@scripts/onboarding/sections/summary.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wizard CLI entry point with config generation</name>
  <files>
    src/cli/onboarding_wizard.py
  </files>
  <action>
Create `src/cli/onboarding_wizard.py` -- the Layer 3 CLI that orchestrates the entire onboarding flow.

**Ensure src/cli/__init__.py exists** (create if missing, can be empty).

**Structure:**

1. **Imports:**
   - All 8 section runners from `src.utils.onboarding_sections`
   - `OnboardingState`, `SectionName` from `src.models.onboarding_inputs`
   - `UserDataInput` and all sub-models from `src.models.yaml_generation_inputs`
   - `YAMLGenerator`, `write_config_files` from `src.utils.yaml_generator`
   - `argparse`, `sys`, `shutil`, `pathlib.Path`, `datetime`

2. **`SECTION_ORDER` list:** Ordered list of (SectionName, runner_function) tuples defining the 8-section flow:
   ```
   liquid_assets -> investments -> cash_flow -> debt -> preferences -> broker -> env_setup -> summary
   ```

3. **`convert_state_to_user_data(state: OnboardingState, project_root: str) -> UserDataInput`:**
   - Reads state.data sections and constructs UserDataInput from existing Pydantic models
   - Maps wizard-collected data to model fields:
     - identity: user_name from env_setup data, language from env_setup data
     - liquid_assets: from liquid_assets data (average_yield already in decimal from section runner)
     - portfolio: from investments data (map allocation_strategy and risk_tolerance strings to enum instances)
     - cash_flow: from cash_flow data
     - debt: from debt data (rates already in decimal from section runner)
     - preferences: from preferences data (map investment_philosophy string to enum instance)
     - mcp: from env_setup data (has_alphavantage, alphavantage_key, etc.)
     - project_root: passed parameter (str(Path.cwd()))
   - Handle missing/skipped sections gracefully: use sensible defaults where Pydantic allows, or raise clear error if required data is missing
   - **Enum conversion (critical):** Plan 01 section runners store human-readable strings in state.data (what questionary returns, e.g., "aggressive", "growth"). This function converts those strings to actual enum instances for UserDataInput. Use the enum class to look up by value: `RiskTolerance(state_data["risk_tolerance"])` which maps "aggressive" -> `RiskTolerance.AGGRESSIVE`. Similarly for `AllocationStrategy(...)` and `InvestmentPhilosophy(...)`. If the string doesn't match any enum value, fall back to a sensible default and print a warning.

4. **`generate_config_files(user_data: UserDataInput, project_root: Path) -> None`:**
   - Initialize YAMLGenerator with template dir: `"scripts/onboarding/modules/templates"`
   - Call `generator.generate_all_configs(user_data)`
   - **Output file locations** (critical -- get these right):
     - user-profile.yaml -> `fin-guru-private/fin-guru/data/user-profile.yaml` (private, gitignored)
     - config.yaml -> `fin-guru-private/fin-guru/config.yaml` (private)
     - system-context.md -> `fin-guru-private/fin-guru/data/system-context.md` (private)
     - CLAUDE.md -> `{project_root}/CLAUDE.md` (project root, replaces template)
     - .env -> `{project_root}/.env` (project root, gitignored)
     - mcp.json -> `{project_root}/.claude/mcp.json` (project root)
   - Use write_config_files(output, base_dir="fin-guru-private") for the private files
   - For CLAUDE.md: backup existing to CLAUDE.md.backup before overwriting. Write explicitly:
     ```python
     Path(project_root / 'CLAUDE.md').write_text(output.claude_md, encoding='utf-8')
     ```
   - For .env: backup existing to .env.backup. Write explicitly:
     ```python
     Path(project_root / '.env').write_text(output.env_file, encoding='utf-8')
     ```
   - For mcp.json: backup existing .claude/mcp.json to .claude/mcp.json.backup. Write explicitly:
     ```python
     Path(project_root / '.claude' / 'mcp.json').write_text(output.mcp_json, encoding='utf-8')
     ```
   - Print list of generated files with paths after completion
   - Print "merge instructions" note for mcp.json: tell user to manually merge if they had custom MCP config

5. **`run_wizard() -> None`:**
   - Print welcome banner: "Finance Guru Onboarding Wizard"
   - Create fresh OnboardingState
   - Iterate through SECTION_ORDER, calling each runner with state
   - After summary section confirms, call convert_state_to_user_data
   - Call generate_config_files
   - Print completion message with next steps
   - Handle KeyboardInterrupt at top level: print "Onboarding interrupted. Progress not saved (save/resume is Phase 4)." and exit gracefully

6. **`main()` with argparse:**
   - `--dry-run`: Run wizard but skip file generation (print what WOULD be generated)
   - No other flags needed for Phase 3 (save/resume comes in Phase 4)
   - Call run_wizard()

7. **`if __name__ == "__main__": main()`**

**Important notes:**
- The write_config_files() function writes to `{base_dir}/fin-guru/data/user-profile.yaml` etc. So calling it with base_dir="fin-guru-private" results in `fin-guru-private/fin-guru/data/user-profile.yaml`. This is correct.
- For CLAUDE.md, .env, and mcp.json that go to project root or .claude/, write them separately using Path(...).write_text() after generating via the YAMLGenerator. Note that write_config_files also writes these to base_dir -- the separate writes override those with the correct project-root locations.
- Do NOT modify write_config_files() or any existing code. Write the project-root files separately.
  </action>
  <verify>
```bash
# Verify the CLI module compiles and imports correctly
uv run python -m py_compile src/cli/onboarding_wizard.py

# Verify the key function exists and module structure is correct
uv run python -c "
from src.cli.onboarding_wizard import convert_state_to_user_data, generate_config_files, SECTION_ORDER
print(f'Section order: {len(SECTION_ORDER)} sections')
assert len(SECTION_ORDER) == 8, f'Expected 8 sections, got {len(SECTION_ORDER)}'
print('Wizard module structure verified')
"

# Verify --help works
uv run python src/cli/onboarding_wizard.py --help
```
All three commands exit 0.
  </verify>
  <done>
Wizard CLI exists at src/cli/onboarding_wizard.py with: 8-section orchestration, state-to-UserDataInput conversion with explicit string-to-enum mapping (RiskTolerance("aggressive") etc.), config file generation to correct paths (private files to fin-guru-private/, CLAUDE.md and .env to project root, mcp.json to .claude/ via explicit Path.write_text), backup of existing files before overwriting, and argparse entry point with --dry-run flag.
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix hook profile path and verify runtime agent config loading</name>
  <files>
    .claude/hooks/load-fin-core-config.ts
  </files>
  <action>
**Problem:** The session-start hook at `.claude/hooks/load-fin-core-config.ts` reads user-profile.yaml from `fin-guru/data/user-profile.yaml` (line 167), but the onboarding wizard generates it to `fin-guru-private/fin-guru/data/user-profile.yaml`. This path mismatch means agents will NOT see the generated profile after onboarding, breaking ONBD-17 ("Finance Guru agents load the generated user-profile.yaml and address the user by their configured name").

**Fix the profilePath (and related paths) in load-fin-core-config.ts:**

1. Change line 166 (configPath):
   ```typescript
   // BEFORE:
   const configPath = join(projectRoot, 'fin-guru/config.yaml');
   // AFTER:
   const configPath = join(projectRoot, 'fin-guru-private/fin-guru/config.yaml');
   ```

2. Change line 167 (profilePath):
   ```typescript
   // BEFORE:
   const profilePath = join(projectRoot, 'fin-guru/data/user-profile.yaml');
   // AFTER:
   const profilePath = join(projectRoot, 'fin-guru-private/fin-guru/data/user-profile.yaml');
   ```

3. Change line 168 (systemContextPath):
   ```typescript
   // BEFORE:
   const systemContextPath = join(projectRoot, 'fin-guru/data/system-context.md');
   // AFTER:
   const systemContextPath = join(projectRoot, 'fin-guru-private/fin-guru/data/system-context.md');
   ```

**Why all three paths change:** The wizard's `write_config_files(output, base_dir="fin-guru-private")` writes ALL private config files under `fin-guru-private/`. The hook must read from the same location the wizard writes to. The `fin-guru/` directory at the project root contains the CURRENT owner's live data (which will be migrated to `fin-guru-private/` as part of onboarding adoption).

**Verify the runtime chain is complete after this fix:**
- Wizard generates `fin-guru-private/fin-guru/data/user-profile.yaml` with `user_name: {name}`
- Hook reads from `fin-guru-private/fin-guru/data/user-profile.yaml` at session start
- Hook injects profile content into Claude's system context as "USER PROFILE" section
- Agents see user_name in the loaded profile and address user accordingly
- The `{user_name}` path variable referenced in agent .md files is populated from this loaded profile

**Do NOT change:**
- The skill path (line 165) -- `.claude/skills/fin-core/SKILL.md` is correctly at project root
- The updates directory (line 169) -- `notebooks/updates` is correctly at project root
- Any other logic in the hook (file recency checks, alert generation, etc.)
  </action>
  <verify>
```bash
# Verify the hook compiles with bun
bun build .claude/hooks/load-fin-core-config.ts --no-bundle --outdir /tmp/hook-test 2>&1 | tail -1

# Verify the path strings are correct in the source
grep "fin-guru-private" .claude/hooks/load-fin-core-config.ts | wc -l
# Should show 3 (configPath, profilePath, systemContextPath)

# Verify old path is gone
grep "join(projectRoot, 'fin-guru/" .claude/hooks/load-fin-core-config.ts | grep -v "fin-guru-private" | wc -l
# Should show 0 (no remaining old-style paths for config/profile/context)
```
  </verify>
  <done>
Hook reads user-profile.yaml, config.yaml, and system-context.md from `fin-guru-private/fin-guru/` -- matching the wizard's output location. The runtime chain is complete: wizard generates profile -> hook loads profile at session start -> agents see user_name in injected context -> agents address user by configured name (ONBD-17 satisfied).
  </done>
</task>

<task type="auto">
  <name>Task 3: Comprehensive test suite for onboarding stack</name>
  <files>
    tests/python/test_onboarding_validators.py
    tests/python/test_onboarding_sections.py
    tests/python/test_onboarding_wizard.py
  </files>
  <action>
Write tests for all three layers of the onboarding stack. All tests mock questionary at the function level (NOT stdin). Follow existing test patterns from tests/python/test_yaml_generation.py.

**File 1: tests/python/test_onboarding_validators.py**

Test the domain validators and ask_with_retry wrapper:

1. `test_validate_currency_valid_formats()`:
   - "10000" -> 10000.0
   - "$10,000" -> 10000.0
   - "$10,000.50" -> 10000.50
   - "0" -> 0.0

2. `test_validate_currency_invalid()`:
   - "abc" raises ValueError
   - "-100" raises ValueError
   - "" raises ValueError

3. `test_validate_percentage_valid()`:
   - "4.5" -> 4.5
   - "4.5%" -> 4.5
   - "0" -> 0.0
   - "100" -> 100.0

4. `test_validate_percentage_invalid()`:
   - "101" raises ValueError (if >100 check exists)
   - "-1" raises ValueError
   - "abc" raises ValueError

5. `test_validate_positive_integer_valid()`:
   - "3" -> 3
   - "1" -> 1

6. `test_validate_positive_integer_invalid()`:
   - "0" raises ValueError
   - "-1" raises ValueError
   - "abc" raises ValueError
   - "3.5" raises ValueError

7. `test_ask_with_retry_valid_first_attempt(mocker)`:
   - Mock prompt_fn to return "10000"
   - Use validate_currency as validator
   - Assert returns 10000.0
   - Assert prompt_fn called once

8. `test_ask_with_retry_valid_after_retries(mocker)`:
   - Mock prompt_fn to return "abc", "xyz", "10000" (valid on 3rd try)
   - Assert returns 10000.0

9. `test_ask_with_retry_skip_after_max_retries(mocker)`:
   - Mock prompt_fn to return "abc" 3 times
   - Mock questionary.confirm to return True (skip)
   - Assert returns default_on_skip value

10. `test_ask_with_retry_ctrl_c_returns_default(mocker)`:
    - Mock prompt_fn to return None
    - Assert returns default_on_skip

**File 2: tests/python/test_onboarding_sections.py**

Test individual section runners with mocked questionary:

1. `test_liquid_assets_section(mocker)`:
   - Mock questionary.text().ask() side_effect: ["15000", "3", "4.5", ""] (total, count, yield, structure skip)
   - Mock questionary.confirm if needed for skip logic
   - Call run_liquid_assets_section with fresh OnboardingState
   - Assert state.data["liquid_assets"]["total"] == 15000.0
   - Assert state.data["liquid_assets"]["average_yield"] == 0.045 (decimal)
   - Assert "liquid_assets" in state.completed_sections or state.is_section_complete(SectionName.LIQUID_ASSETS)

2. `test_cash_flow_section(mocker)`:
   - Mock 5 questionary.text().ask() responses: income, fixed, variable, savings, investment
   - Assert all 5 fields stored correctly in state.data["cash_flow"]

3. `test_preferences_section(mocker)`:
   - Mock questionary.select().ask() for philosophy
   - Mock questionary.checkbox().ask() for focus areas
   - Mock questionary.text().ask() for emergency months
   - Assert data stored with correct string values (NOT enum instances -- strings are stored, conversion is in wizard)

4. `test_env_setup_section_all_skipped(mocker)`:
   - Mock: user_name "Alex", language "English", confirm False for all API keys
   - Assert state.data["env_setup"]["user_name"] == "Alex"
   - Assert API key fields are absent or False

5. `test_summary_section_confirmed(mocker)`:
   - Pre-populate state.data with mock data for all prior sections
   - Mock questionary.confirm().ask() to return True
   - Assert state.data["summary"]["confirmed"] == True

**Mocking pattern for all section tests:**
```python
# For questionary.text:
mock_text = mocker.patch("src.utils.onboarding_sections.questionary.text")
mock_text.return_value.ask.side_effect = ["value1", "value2", ...]

# For questionary.select:
mock_select = mocker.patch("src.utils.onboarding_sections.questionary.select")
mock_select.return_value.ask.return_value = "selected_value"

# For questionary.confirm:
mock_confirm = mocker.patch("src.utils.onboarding_sections.questionary.confirm")
mock_confirm.return_value.ask.return_value = True

# For questionary.checkbox:
mock_checkbox = mocker.patch("src.utils.onboarding_sections.questionary.checkbox")
mock_checkbox.return_value.ask.return_value = ["choice1", "choice2"]
```

Important: Patch at `src.utils.onboarding_sections.questionary.*` (where it is imported), NOT at `questionary.*`.
Also patch `src.utils.onboarding_validators.questionary.confirm` for the skip-after-retry confirm dialog, since that import is in the validators module.

**File 3: tests/python/test_onboarding_wizard.py**

Integration test for the wizard's data conversion and config generation:

1. `test_convert_state_to_user_data()`:
   - Create OnboardingState with manually populated data dict (simulating completed wizard)
   - Enum fields in state.data should contain human-readable strings (e.g., "aggressive", "growth") -- matching what section runners store
   - Call convert_state_to_user_data(state, "/tmp/test-project")
   - Assert returned UserDataInput has correct identity, liquid_assets, portfolio, etc.
   - Assert enum fields are actual enum instances (not strings) -- verifying the string-to-enum conversion works
   - Assert project_root is set

2. `test_generate_config_files(tmp_path)`:
   - Create a UserDataInput with test data
   - Copy template files to a temp location OR point template_dir at real templates
   - Call generate_config_files with tmp_path as project_root
   - Assert fin-guru-private/fin-guru/data/user-profile.yaml exists
   - Assert CLAUDE.md exists at project root (tmp_path)
   - Assert .env exists at project root
   - Assert .claude/mcp.json exists at project root (tmp_path / '.claude' / 'mcp.json')
   - Assert generated files contain user_name (not {{user_name}} placeholder)

3. `test_generate_config_files_backs_up_existing(tmp_path)`:
   - Create fake existing CLAUDE.md, .env, and .claude/mcp.json at tmp_path
   - Call generate_config_files
   - Assert CLAUDE.md.backup exists
   - Assert .env.backup exists
   - Assert .claude/mcp.json.backup exists

4. `test_section_order_has_eight_entries()`:
   - Assert len(SECTION_ORDER) == 8
   - Assert first is liquid_assets, last is summary

Use `pytest` fixtures (tmp_path built-in) for file system tests. Use `mocker` from pytest-mock for questionary mocking.
  </action>
  <verify>
```bash
# Run only the new onboarding tests
uv run pytest tests/python/test_onboarding_validators.py tests/python/test_onboarding_sections.py tests/python/test_onboarding_wizard.py -v

# Run the full test suite to check for regressions
uv run pytest tests/python/ -x -q
```
All new tests pass. Full test suite passes without regressions.
  </verify>
  <done>
Three test files cover the onboarding stack: validators (currency/percentage/integer parsing, retry-with-skip logic), sections (mocked questionary prompts for liquid assets, cash flow, preferences, env setup, summary -- verifying strings stored not enum instances), and wizard integration (state-to-model conversion with string-to-enum mapping verified, config file generation to correct paths including explicit mcp.json at .claude/mcp.json, backup of all existing files). All existing tests continue to pass.
  </done>
</task>

<task type="auto">
  <name>Task 4: Agent genericization for user_name</name>
  <files>
    Determined by grep -- any agent files containing hardcoded "the owner's name"
  </files>
  <action>
Scan all agent definition files for hardcoded personal references and replace with generic {user_name} template variable or remove the reference.

**Step 1: Find all files with hardcoded "the owner's name" in agent definitions:**
```bash
grep -rl "the owner's name" .claude/commands/fin-guru/ fin-guru/ --include="*.md" --include="*.yaml" --include="*.yml" 2>/dev/null
```

Also check for references in the template CLAUDE.md:
```bash
grep -rl "the owner's name" scripts/onboarding/modules/templates/ 2>/dev/null
```

**Step 2: For each file found:**
- If it is an agent definition (.claude/commands/fin-guru/agents/*.md): Replace "the owner's name" with "{user_name}" in contexts where the agent addresses the user. Keep the agent personality/name unchanged (e.g., "Cassandra Holt" stays).
- If it is in fin-guru/data/ or fin-guru/config/: These are the current owner's config files. Do NOT modify these -- they will be replaced by template-generated files for new users. The existing user-profile.yaml at fin-guru/data/ is the owner's data.
- If it is in templates/: Ensure the template uses {{user_name}} not hardcoded names.

**Step 3: Verify agent files load {user_name} from config at runtime.**

The runtime chain that makes {user_name} work in agents:
1. Onboarding wizard collects user_name and generates `fin-guru-private/fin-guru/data/user-profile.yaml` containing `user_name: {name}`
2. `.claude/hooks/load-fin-core-config.ts` reads this file at session start (path fixed in Task 2)
3. The hook injects the profile content into Claude's system context
4. Agent .md files reference {user_name} which is resolved from the loaded profile

Verify this chain is intact by confirming:
- The hook reads from `fin-guru-private/fin-guru/data/user-profile.yaml` (fixed in Task 2)
- Agent files that used "the owner's name" now use {user_name}
- The user-profile.template.yaml contains `user_name: {{user_name}}`

**Important:** ONBD-17 says "Finance Guru agents work with generic user profile (uses {user_name} not hardcoded names)." The goal is that agents work for ANY user who completes onboarding, not just the original owner.

**Scope limit:** Only change agent definition files and templates. Do NOT change:
- Existing yaml_generation_inputs.py
- Existing yaml_generator.py
- Any Python source files
- fin-guru/data/user-profile.yaml (owner's live data)
  </action>
  <verify>
```bash
# After changes, verify no "the owner's name" remains in agent definitions
grep -r "the owner's name" .claude/commands/fin-guru/ --include="*.md" || echo "No hardcoded personal names in agent files"

# Verify templates use {{user_name}}
grep -c "user_name" scripts/onboarding/modules/templates/CLAUDE.template.md

# Verify hook reads from correct path (fin-guru-private)
grep "fin-guru-private" .claude/hooks/load-fin-core-config.ts | wc -l
# Should show 3
```
First grep returns nothing (or echo fires). Second grep shows at least 1 match. Third grep shows 3.
  </verify>
  <done>
All agent definition files use generic {user_name} or "the user" instead of hardcoded personal names. Templates use {{user_name}} template variables. The runtime chain is verified end-to-end: wizard generates profile with user_name -> hook loads from fin-guru-private/ (path fixed in Task 2) -> agents see {user_name} in loaded context -> agents address any user by their configured name.
  </done>
</task>

</tasks>

<verification>
**Full verification sequence:**

1. All new files compile:
```bash
uv run python -m py_compile src/cli/onboarding_wizard.py
```

2. Hook compiles:
```bash
bun build .claude/hooks/load-fin-core-config.ts --no-bundle --outdir /tmp/hook-test 2>&1 | tail -1
```

3. All new tests pass:
```bash
uv run pytest tests/python/test_onboarding_validators.py tests/python/test_onboarding_sections.py tests/python/test_onboarding_wizard.py -v
```

4. Full test suite -- no regressions:
```bash
uv run pytest tests/python/ -x -q
```

5. Wizard CLI runs (--help):
```bash
uv run python src/cli/onboarding_wizard.py --help
```

6. No hardcoded "the owner's name" in agent files:
```bash
grep -r "the owner's name" .claude/commands/fin-guru/ --include="*.md" | wc -l
# Should be 0
```

7. Hook reads from fin-guru-private/:
```bash
grep "fin-guru-private/fin-guru" .claude/hooks/load-fin-core-config.ts | wc -l
# Should be 3 (configPath, profilePath, systemContextPath)
```

8. mcp.json write uses explicit Path:
```bash
grep -c "mcp.json.*write_text\|write_text.*mcp.json" src/cli/onboarding_wizard.py
# Should be >= 1
```

9. questionary in dependencies:
```bash
grep "questionary" pyproject.toml
```
</verification>

<success_criteria>
1. `uv run python src/cli/onboarding_wizard.py --help` shows usage with --dry-run flag
2. Wizard orchestrates all 8 sections in correct order (liquid_assets through summary)
3. convert_state_to_user_data produces a valid UserDataInput from completed wizard state, with strings converted to enum instances
4. Config files are generated to correct locations: user-profile.yaml in fin-guru-private/, CLAUDE.md and .env at project root
5. Existing CLAUDE.md, .env, and .claude/mcp.json are backed up before overwriting (.backup extension)
6. MCP.json generated at .claude/mcp.json via explicit `Path('.claude/mcp.json').write_text(output.mcp_json)` with backup and merge instructions printed
7. Hook at .claude/hooks/load-fin-core-config.ts reads profile from fin-guru-private/fin-guru/data/user-profile.yaml (matching wizard output)
8. Tests cover: validators (happy path + error cases), sections (mocked questionary, verify string storage for enums), wizard (data conversion with string-to-enum mapping + file generation + backup including mcp.json)
9. All 365+ existing tests pass without regression
10. Agent files use generic {user_name} not hardcoded personal names
11. Runtime chain verified: wizard output -> hook reads -> agents see user_name
12. No modifications to existing yaml_generation_inputs.py or yaml_generator.py
</success_criteria>

<output>
After completion, create `.planning/phases/03-onboarding-wizard/03-02-SUMMARY.md`
</output>
