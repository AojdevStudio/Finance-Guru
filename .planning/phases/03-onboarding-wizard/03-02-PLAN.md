---
phase: 03-onboarding-wizard
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/cli/onboarding_wizard.py
  - tests/python/test_onboarding_validators.py
  - tests/python/test_onboarding_sections.py
  - tests/python/test_onboarding_wizard.py
autonomous: true

must_haves:
  truths:
    - "User completes 8-section interactive onboarding and a valid user-profile.yaml is generated in fin-guru-private/ with their financial data"
    - "Entering invalid input shows a clear error and re-prompts up to 3 times, then offers a skip option"
    - "CLAUDE.md is generated with the user's name and correct project-root path (no hardcoded Ossie or absolute paths)"
    - ".env file is created with optional API keys (user can skip all keys and system still functions)"
    - "MCP.json is generated from template with backup of existing file"
    - "Finance Guru agents load the generated user-profile.yaml and address the user by their configured name"
  artifacts:
    - path: "src/cli/onboarding_wizard.py"
      provides: "Main wizard entry point: orchestrates 8 sections, converts state to UserDataInput, generates all config files"
      min_lines: 100
    - path: "tests/python/test_onboarding_validators.py"
      provides: "Unit tests for retry-with-skip wrapper and all domain validators"
      min_lines: 60
    - path: "tests/python/test_onboarding_sections.py"
      provides: "Unit tests for section runners with mocked questionary prompts"
      min_lines: 80
    - path: "tests/python/test_onboarding_wizard.py"
      provides: "Integration test for full wizard flow with mocked questionary"
      min_lines: 50
  key_links:
    - from: "src/cli/onboarding_wizard.py"
      to: "src/utils/onboarding_sections.py"
      via: "imports all 8 run_*_section functions"
      pattern: "from src\\.utils\\.onboarding_sections import"
    - from: "src/cli/onboarding_wizard.py"
      to: "src/models/yaml_generation_inputs.py"
      via: "converts OnboardingState.data to UserDataInput for generation"
      pattern: "UserDataInput\\("
    - from: "src/cli/onboarding_wizard.py"
      to: "src/utils/yaml_generator.py"
      via: "calls YAMLGenerator.generate_all_configs() and write_config_files()"
      pattern: "generate_all_configs|write_config_files"
    - from: "tests/python/test_onboarding_sections.py"
      to: "questionary"
      via: "mocker.patch at questionary function level (not stdin)"
      pattern: "mocker\\.patch.*questionary"
---

<objective>
Build the wizard CLI entry point that orchestrates all 8 sections, converts collected data into the existing Pydantic models, generates all config files (user-profile.yaml, CLAUDE.md, .env, MCP JSON) to the correct output locations, and write comprehensive tests for the entire onboarding stack.

Purpose: This completes the interactive onboarding wizard (ONBD-01, ONBD-04, ONBD-07, ONBD-08, ONBD-09) by wiring the section runners from Plan 01 into a complete CLI flow that produces real configuration files. Tests verify validators, sections, and the full wizard pipeline (ONBD-02, XC-04).

Output: Working CLI at `src/cli/onboarding_wizard.py` callable via `uv run python src/cli/onboarding_wizard.py`, plus 3 test files covering validators, sections, and integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-onboarding-wizard/03-RESEARCH.md
@.planning/phases/03-onboarding-wizard/03-01-SUMMARY.md

# Files from Plan 01 (created by this plan's dependency)
@src/models/onboarding_inputs.py
@src/utils/onboarding_validators.py
@src/utils/onboarding_sections.py

# Existing Layer 1+2 (reused, NOT modified)
@src/models/yaml_generation_inputs.py
@src/utils/yaml_generator.py
@src/utils/yaml_generator_cli.py

# Templates (used by YAMLGenerator)
# scripts/onboarding/modules/templates/ contains: user-profile.template.yaml, CLAUDE.template.md, env.template, mcp.template.json, config.template.yaml, system-context.template.md

# Existing test patterns
@tests/python/test_yaml_generation.py

# TypeScript env-setup and summary sections (reference for output behavior)
@scripts/onboarding/sections/env-setup.ts
@scripts/onboarding/sections/summary.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wizard CLI entry point with config generation</name>
  <files>
    src/cli/onboarding_wizard.py
  </files>
  <action>
Create `src/cli/onboarding_wizard.py` -- the Layer 3 CLI that orchestrates the entire onboarding flow.

**Ensure src/cli/__init__.py exists** (create if missing, can be empty).

**Structure:**

1. **Imports:**
   - All 8 section runners from `src.utils.onboarding_sections`
   - `OnboardingState`, `SectionName` from `src.models.onboarding_inputs`
   - `UserDataInput` and all sub-models from `src.models.yaml_generation_inputs`
   - `YAMLGenerator`, `write_config_files` from `src.utils.yaml_generator`
   - `argparse`, `sys`, `shutil`, `pathlib.Path`, `datetime`

2. **`SECTION_ORDER` list:** Ordered list of (SectionName, runner_function) tuples defining the 8-section flow:
   ```
   liquid_assets -> investments -> cash_flow -> debt -> preferences -> broker -> env_setup -> summary
   ```

3. **`convert_state_to_user_data(state: OnboardingState, project_root: str) -> UserDataInput`:**
   - Reads state.data sections and constructs UserDataInput from existing Pydantic models
   - Maps wizard-collected data to model fields:
     - identity: user_name from env_setup data, language from env_setup data
     - liquid_assets: from liquid_assets data (average_yield already in decimal from section runner)
     - portfolio: from investments data (map allocation_strategy and risk_tolerance to enums)
     - cash_flow: from cash_flow data
     - debt: from debt data (rates already in decimal from section runner)
     - preferences: from preferences data (map investment_philosophy to enum)
     - mcp: from env_setup data (has_alphavantage, alphavantage_key, etc.)
     - project_root: passed parameter (str(Path.cwd()))
   - Handle missing/skipped sections gracefully: use sensible defaults where Pydantic allows, or raise clear error if required data is missing
   - Convert enum string values back to actual enum instances (e.g., "aggressive" -> RiskTolerance.AGGRESSIVE)

4. **`generate_config_files(user_data: UserDataInput, project_root: Path) -> None`:**
   - Initialize YAMLGenerator with template dir: `"scripts/onboarding/modules/templates"`
   - Call `generator.generate_all_configs(user_data)`
   - **Output file locations** (critical -- get these right):
     - user-profile.yaml -> `fin-guru-private/fin-guru/data/user-profile.yaml` (private, gitignored)
     - config.yaml -> `fin-guru-private/fin-guru/config.yaml` (private)
     - system-context.md -> `fin-guru-private/fin-guru/data/system-context.md` (private)
     - CLAUDE.md -> `{project_root}/CLAUDE.md` (project root, replaces template)
     - .env -> `{project_root}/.env` (project root, gitignored)
     - mcp.json -> `{project_root}/.claude/mcp.json` (project root)
   - Use write_config_files(output, base_dir="fin-guru-private") for the private files
   - For CLAUDE.md: backup existing to CLAUDE.md.backup before overwriting, write output.claude_md to project root
   - For .env: backup existing to .env.backup, write output.env_file to project root
   - For mcp.json: backup existing .claude/mcp.json to .claude/mcp.json.backup, write output.mcp_json
   - Print list of generated files with paths after completion
   - Print "merge instructions" note for mcp.json: tell user to manually merge if they had custom MCP config

5. **`run_wizard() -> None`:**
   - Print welcome banner: "Finance Guru Onboarding Wizard"
   - Create fresh OnboardingState
   - Iterate through SECTION_ORDER, calling each runner with state
   - After summary section confirms, call convert_state_to_user_data
   - Call generate_config_files
   - Print completion message with next steps
   - Handle KeyboardInterrupt at top level: print "Onboarding interrupted. Progress not saved (save/resume is Phase 4)." and exit gracefully

6. **`main()` with argparse:**
   - `--dry-run`: Run wizard but skip file generation (print what WOULD be generated)
   - No other flags needed for Phase 3 (save/resume comes in Phase 4)
   - Call run_wizard()

7. **`if __name__ == "__main__": main()`**

**Important notes:**
- The write_config_files() function writes to `{base_dir}/fin-guru/data/user-profile.yaml` etc. So calling it with base_dir="fin-guru-private" results in `fin-guru-private/fin-guru/data/user-profile.yaml`. This is correct.
- For CLAUDE.md, .env, and mcp.json that go to project root or .claude/, write them separately using Path.write_text() after generating via the YAMLGenerator.
- Do NOT modify write_config_files() or any existing code. Write the project-root files separately.
  </action>
  <verify>
```bash
# Verify the CLI module compiles and imports correctly
uv run python -m py_compile src/cli/onboarding_wizard.py

# Verify the key function exists and module structure is correct
uv run python -c "
from src.cli.onboarding_wizard import convert_state_to_user_data, generate_config_files, SECTION_ORDER
print(f'Section order: {len(SECTION_ORDER)} sections')
assert len(SECTION_ORDER) == 8, f'Expected 8 sections, got {len(SECTION_ORDER)}'
print('Wizard module structure verified')
"

# Verify --help works
uv run python src/cli/onboarding_wizard.py --help
```
All three commands exit 0.
  </verify>
  <done>
Wizard CLI exists at src/cli/onboarding_wizard.py with: 8-section orchestration, state-to-UserDataInput conversion with enum mapping, config file generation to correct paths (private files to fin-guru-private/, CLAUDE.md and .env to project root), backup of existing files before overwriting, and argparse entry point with --dry-run flag.
  </done>
</task>

<task type="auto">
  <name>Task 2: Comprehensive test suite for onboarding stack</name>
  <files>
    tests/python/test_onboarding_validators.py
    tests/python/test_onboarding_sections.py
    tests/python/test_onboarding_wizard.py
  </files>
  <action>
Write tests for all three layers of the onboarding stack. All tests mock questionary at the function level (NOT stdin). Follow existing test patterns from tests/python/test_yaml_generation.py.

**File 1: tests/python/test_onboarding_validators.py**

Test the domain validators and ask_with_retry wrapper:

1. `test_validate_currency_valid_formats()`:
   - "10000" -> 10000.0
   - "$10,000" -> 10000.0
   - "$10,000.50" -> 10000.50
   - "0" -> 0.0

2. `test_validate_currency_invalid()`:
   - "abc" raises ValueError
   - "-100" raises ValueError
   - "" raises ValueError

3. `test_validate_percentage_valid()`:
   - "4.5" -> 4.5
   - "4.5%" -> 4.5
   - "0" -> 0.0
   - "100" -> 100.0

4. `test_validate_percentage_invalid()`:
   - "101" raises ValueError (if >100 check exists)
   - "-1" raises ValueError
   - "abc" raises ValueError

5. `test_validate_positive_integer_valid()`:
   - "3" -> 3
   - "1" -> 1

6. `test_validate_positive_integer_invalid()`:
   - "0" raises ValueError
   - "-1" raises ValueError
   - "abc" raises ValueError
   - "3.5" raises ValueError

7. `test_ask_with_retry_valid_first_attempt(mocker)`:
   - Mock prompt_fn to return "10000"
   - Use validate_currency as validator
   - Assert returns 10000.0
   - Assert prompt_fn called once

8. `test_ask_with_retry_valid_after_retries(mocker)`:
   - Mock prompt_fn to return "abc", "xyz", "10000" (valid on 3rd try)
   - Assert returns 10000.0

9. `test_ask_with_retry_skip_after_max_retries(mocker)`:
   - Mock prompt_fn to return "abc" 3 times
   - Mock questionary.confirm to return True (skip)
   - Assert returns default_on_skip value

10. `test_ask_with_retry_ctrl_c_returns_default(mocker)`:
    - Mock prompt_fn to return None
    - Assert returns default_on_skip

**File 2: tests/python/test_onboarding_sections.py**

Test individual section runners with mocked questionary:

1. `test_liquid_assets_section(mocker)`:
   - Mock questionary.text().ask() side_effect: ["15000", "3", "4.5", ""] (total, count, yield, structure skip)
   - Mock questionary.confirm if needed for skip logic
   - Call run_liquid_assets_section with fresh OnboardingState
   - Assert state.data["liquid_assets"]["total"] == 15000.0
   - Assert state.data["liquid_assets"]["average_yield"] == 0.045 (decimal)
   - Assert "liquid_assets" in state.completed_sections or state.is_section_complete(SectionName.LIQUID_ASSETS)

2. `test_cash_flow_section(mocker)`:
   - Mock 5 questionary.text().ask() responses: income, fixed, variable, savings, investment
   - Assert all 5 fields stored correctly in state.data["cash_flow"]

3. `test_preferences_section(mocker)`:
   - Mock questionary.select().ask() for philosophy
   - Mock questionary.checkbox().ask() for focus areas
   - Mock questionary.text().ask() for emergency months
   - Assert data stored with correct enum mapping

4. `test_env_setup_section_all_skipped(mocker)`:
   - Mock: user_name "Alex", language "English", confirm False for all API keys
   - Assert state.data["env_setup"]["user_name"] == "Alex"
   - Assert API key fields are absent or False

5. `test_summary_section_confirmed(mocker)`:
   - Pre-populate state.data with mock data for all prior sections
   - Mock questionary.confirm().ask() to return True
   - Assert state.data["summary"]["confirmed"] == True

**Mocking pattern for all section tests:**
```python
# For questionary.text:
mock_text = mocker.patch("src.utils.onboarding_sections.questionary.text")
mock_text.return_value.ask.side_effect = ["value1", "value2", ...]

# For questionary.select:
mock_select = mocker.patch("src.utils.onboarding_sections.questionary.select")
mock_select.return_value.ask.return_value = "selected_value"

# For questionary.confirm:
mock_confirm = mocker.patch("src.utils.onboarding_sections.questionary.confirm")
mock_confirm.return_value.ask.return_value = True

# For questionary.checkbox:
mock_checkbox = mocker.patch("src.utils.onboarding_sections.questionary.checkbox")
mock_checkbox.return_value.ask.return_value = ["choice1", "choice2"]
```

Important: Patch at `src.utils.onboarding_sections.questionary.*` (where it is imported), NOT at `questionary.*`.
Also patch `src.utils.onboarding_validators.questionary.confirm` for the skip-after-retry confirm dialog, since that import is in the validators module.

**File 3: tests/python/test_onboarding_wizard.py**

Integration test for the wizard's data conversion and config generation:

1. `test_convert_state_to_user_data()`:
   - Create OnboardingState with manually populated data dict (simulating completed wizard)
   - Call convert_state_to_user_data(state, "/tmp/test-project")
   - Assert returned UserDataInput has correct identity, liquid_assets, portfolio, etc.
   - Assert enum fields are actual enum instances (not strings)
   - Assert project_root is set

2. `test_generate_config_files(tmp_path)`:
   - Create a UserDataInput with test data
   - Copy template files to a temp location OR point template_dir at real templates
   - Call generate_config_files with tmp_path as project_root
   - Assert fin-guru-private/fin-guru/data/user-profile.yaml exists
   - Assert CLAUDE.md exists at project root (tmp_path)
   - Assert .env exists at project root
   - Assert generated files contain user_name (not {{user_name}} placeholder)

3. `test_generate_config_files_backs_up_existing(tmp_path)`:
   - Create fake existing CLAUDE.md and .env at tmp_path
   - Call generate_config_files
   - Assert CLAUDE.md.backup exists
   - Assert .env.backup exists

4. `test_section_order_has_eight_entries()`:
   - Assert len(SECTION_ORDER) == 8
   - Assert first is liquid_assets, last is summary

Use `pytest` fixtures (tmp_path built-in) for file system tests. Use `mocker` from pytest-mock for questionary mocking.
  </action>
  <verify>
```bash
# Run only the new onboarding tests
uv run pytest tests/python/test_onboarding_validators.py tests/python/test_onboarding_sections.py tests/python/test_onboarding_wizard.py -v

# Run the full test suite to check for regressions
uv run pytest tests/python/ -x -q
```
All new tests pass. Full test suite passes without regressions.
  </verify>
  <done>
Three test files cover the onboarding stack: validators (currency/percentage/integer parsing, retry-with-skip logic), sections (mocked questionary prompts for liquid assets, cash flow, preferences, env setup, summary), and wizard integration (state-to-model conversion, config file generation to correct paths, backup of existing files). All existing tests continue to pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Agent genericization for user_name</name>
  <files>
    Determined by grep -- any agent files containing hardcoded "Ossie"
  </files>
  <action>
Scan all agent definition files for hardcoded personal references and replace with generic {user_name} template variable or remove the reference.

**Step 1: Find all files with hardcoded "Ossie" in agent definitions:**
```bash
grep -rl "Ossie" .claude/commands/fin-guru/ fin-guru/ --include="*.md" --include="*.yaml" --include="*.yml" 2>/dev/null
```

Also check for references in the template CLAUDE.md:
```bash
grep -rl "Ossie" scripts/onboarding/modules/templates/ 2>/dev/null
```

**Step 2: For each file found:**
- If it is an agent definition (.claude/commands/fin-guru/agents/*.md): Replace "Ossie" with "{user_name}" in contexts where the agent addresses the user. Keep the agent personality/name unchanged (e.g., "Cassandra Holt" stays).
- If it is in fin-guru/data/ or fin-guru/config/: These are the current owner's config files. Do NOT modify these -- they will be replaced by template-generated files for new users. The existing user-profile.yaml at fin-guru/data/ is the owner's data.
- If it is in templates/: Ensure the template uses {{user_name}} not hardcoded names.

**Step 3: Verify agent files load {user_name} from config.**

Check how agents currently reference the user's name. The typical pattern in agent .md files is either:
- Direct mention: "Ossie" or "the user"
- Config reference: reads from user-profile.yaml

For each agent file that mentions a hardcoded name, update to use a pattern like "the user" or "{user_name}" depending on context. If the agent already reads user_name from config, no change needed.

**Important:** ONBD-17 says "Finance Guru agents work with generic user profile (uses {user_name} not hardcoded names)." The goal is that agents work for ANY user who completes onboarding, not just the original owner.

**Scope limit:** Only change agent definition files and templates. Do NOT change:
- Existing yaml_generation_inputs.py
- Existing yaml_generator.py
- Any Python source files
- fin-guru/data/user-profile.yaml (owner's live data)
  </action>
  <verify>
```bash
# After changes, verify no "Ossie" remains in agent definitions
grep -r "Ossie" .claude/commands/fin-guru/ --include="*.md" || echo "No hardcoded Ossie in agent files"

# Verify templates use {{user_name}}
grep -c "user_name" scripts/onboarding/modules/templates/CLAUDE.template.md
```
First grep returns nothing (or echo fires). Second grep shows at least 1 match.
  </verify>
  <done>
All agent definition files use generic {user_name} or "the user" instead of hardcoded personal names. Templates use {{user_name}} template variables. Agents will address any user by their configured name after onboarding generates config files.
  </done>
</task>

</tasks>

<verification>
**Full verification sequence:**

1. All new files compile:
```bash
uv run python -m py_compile src/cli/onboarding_wizard.py
```

2. All new tests pass:
```bash
uv run pytest tests/python/test_onboarding_validators.py tests/python/test_onboarding_sections.py tests/python/test_onboarding_wizard.py -v
```

3. Full test suite -- no regressions:
```bash
uv run pytest tests/python/ -x -q
```

4. Wizard CLI runs (--help):
```bash
uv run python src/cli/onboarding_wizard.py --help
```

5. No hardcoded "Ossie" in agent files:
```bash
grep -r "Ossie" .claude/commands/fin-guru/ --include="*.md" | wc -l
# Should be 0
```

6. questionary in dependencies:
```bash
grep "questionary" pyproject.toml
```
</verification>

<success_criteria>
1. `uv run python src/cli/onboarding_wizard.py --help` shows usage with --dry-run flag
2. Wizard orchestrates all 8 sections in correct order (liquid_assets through summary)
3. convert_state_to_user_data produces a valid UserDataInput from completed wizard state
4. Config files are generated to correct locations: user-profile.yaml in fin-guru-private/, CLAUDE.md and .env at project root
5. Existing CLAUDE.md and .env are backed up before overwriting (.backup extension)
6. MCP.json generated at .claude/mcp.json with backup and merge instructions printed
7. Tests cover: validators (happy path + error cases), sections (mocked questionary), wizard (data conversion + file generation + backup)
8. All 365+ existing tests pass without regression
9. Agent files use generic {user_name} not hardcoded personal names
10. No modifications to existing yaml_generation_inputs.py or yaml_generator.py
</success_criteria>

<output>
After completion, create `.planning/phases/03-onboarding-wizard/03-02-SUMMARY.md`
</output>
